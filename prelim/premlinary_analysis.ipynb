{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8188b3fa",
   "metadata": {},
   "source": [
    "# Preliminary CRISPR-Cas13b spacer analysis\n",
    "\n",
    "The aim of this analysis is to get an initial feel on a small subset of Cas13b sequences and see if we see any genomic signals from the spacer sequences. This will also help to establish a analysis pipeline.\n",
    "\n",
    "## Retrieve samples\n",
    "\n",
    "Retrieve samples from Cas13_bacterial_db. Selection criteria are as follows:<br>\n",
    "* Reported to carry the Cas13b gene\n",
    "* Complete genome assembly\n",
    "* Either sequenced by PacBio or Sanger (and presumabliy are high quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329db570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query SQL database\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import modules.database_utils as db_utils\n",
    "from datetime import datetime\n",
    "\n",
    "# connect to the database\n",
    "creds = db_utils.get_credentials()['db_credentials']\n",
    "database = 'cas13_bacterial_db'\n",
    "\n",
    "pg_url = \"postgresql+psycopg2://{0}:{1}@{2}:{3}/{4}\".format(\n",
    "                creds['user'], creds['password'], creds['host'], creds['port'], database)\n",
    "\n",
    "engine = create_engine(pg_url, pool_pre_ping=True, echo=False)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT n.biosampleaccn,\n",
    "        n.organism,\n",
    "        c.cas13subtype,\n",
    "        s.sequencingtechnology,\n",
    "        n.ftppath_genbank\n",
    "    FROM cas13_subtypes AS c\n",
    "    JOIN ncbi_assembly_mono AS n ON c.organism = n.organism\n",
    "    JOIN seq_platform AS s ON n.assemblyname = s.assemblyname\n",
    "    WHERE c.cas13subtype = 'cas13b'\n",
    "        AND n.assemblystatus = 'Complete Genome'\n",
    "            AND n.exclfromrefseq = '[]'\n",
    "            AND (s.sequencingtechnology LIKE '%PacBio%' OR s.sequencingtechnology LIKE '%Sanger%');\n",
    "\"\"\"\n",
    "\n",
    "# with engine.connect() as conn:\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(text(query), conn.execution_options(stream_results=True))\n",
    "\n",
    "timestamp = datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "\n",
    "out_file = f\"prelim/data/ncbi_assembly_{timestamp}.csv\"\n",
    "\n",
    "df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad25d31",
   "metadata": {},
   "source": [
    "This resulted in a initial dataset of 105 samples. The next step is to pull down the fna, gbff and gff files from NCBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e07e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    biosampleaccn                                        organism  \\\n",
      "0    SAMN10691118         Apibacter raozihei (CFB group bacteria)   \n",
      "1    SAMN08913567         Bergeyella cardium (CFB group bacteria)   \n",
      "2    SAMN34037267         Bergeyella cardium (CFB group bacteria)   \n",
      "3    SAMN32105916         Bergeyella cardium (CFB group bacteria)   \n",
      "4    SAMN32105916         Bergeyella cardium (CFB group bacteria)   \n",
      "..            ...                                             ...   \n",
      "100  SAMN31358076  Elizabethkingia anophelis (CFB group bacteria)   \n",
      "101  SAMN04875535  Elizabethkingia anophelis (CFB group bacteria)   \n",
      "102  SAMN03996277  Elizabethkingia anophelis (CFB group bacteria)   \n",
      "103  SAMN03996278  Elizabethkingia anophelis (CFB group bacteria)   \n",
      "104  SAMN04875535  Elizabethkingia anophelis (CFB group bacteria)   \n",
      "\n",
      "    cas13subtype      sequencingtechnology  \\\n",
      "0         cas13b                    PacBio   \n",
      "1         cas13b                    PacBio   \n",
      "2         cas13b                    PacBio   \n",
      "3         cas13b                    PacBio   \n",
      "4         cas13b                    PacBio   \n",
      "..           ...                       ...   \n",
      "100       cas13b  Illumina NovaSeq; PacBio   \n",
      "101       cas13b                    PacBio   \n",
      "102       cas13b          PacBio; Illumina   \n",
      "103       cas13b          PacBio; Illumina   \n",
      "104       cas13b          PacBio; Illumina   \n",
      "\n",
      "                                       ftppath_genbank  \n",
      "0    ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/004...  \n",
      "1    ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/009...  \n",
      "2    ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/029...  \n",
      "3    ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/030...  \n",
      "4    ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/030...  \n",
      "..                                                 ...  \n",
      "100  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/029...  \n",
      "101  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002...  \n",
      "102  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002...  \n",
      "103  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002...  \n",
      "104  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002...  \n",
      "\n",
      "[105 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import modules.genome_utils as genome_utils\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "prelim_data = db_utils.read_table_from_db(out_file)\n",
    "\n",
    "out_file_dir = Path(\"prelim/data/genomes\")\n",
    "\n",
    "if not out_file_dir.exists():\n",
    "    out_file_dir.mkdir(parents=True)\n",
    "\n",
    "for index, row in prelim_data.iterrows():\n",
    "    biosample_accession = row['biosampleaccn']\n",
    "    ftp_path = row['ftppath_genbank']\n",
    "    gff_file_path = genome_utils.get_gff_from_ncbi(ftp_path, biosample_accession, out_file_dir)\n",
    "    if gff_file_path is None:\n",
    "        pass\n",
    "    elif os.path.exists(gff_file_path):\n",
    "        genome_utils.get_fasta_from_ncbi(ftp_path, biosample_accession, out_file_dir)\n",
    "        genome_utils.get_gbff_from_ncbi(ftp_path, biosample_accession, out_file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6443",
   "metadata": {},
   "source": [
    "Extract only samples with Cas13b predicted. This information can be retrieved from the gbff and gff file.<br>\n",
    "\n",
    "Look through files first, generate a master datasheet and only run crispridentify on those in the sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modules.database_utils as db_utils\n",
    "from modules.genome_utils import CasContig\n",
    "\n",
    "df = db_utils.read_table_from_db(\"prelim/data/ncbi_assembly_30-06-2025-10-32-13.csv\")\n",
    "storage = Path(\"/spacers_db/genomes\")\n",
    "\n",
    "cas_type = \"cas13b\"\n",
    "\n",
    "df_output = pd.DataFrame(columns=[\n",
    "    'biosample_accession',\n",
    "    'organism',\n",
    "    'contig_id',\n",
    "    'cas_gene',\n",
    "    'locus_tag',\n",
    "    'orientation',\n",
    "    'start',\n",
    "    'end'\n",
    "])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    biosample_accession = row['biosampleaccn']\n",
    "    print(biosample_accession)\n",
    "    gbff_file = storage / f\"{biosample_accession}.gbff\"\n",
    "    gff_file = storage / f\"{biosample_accession}.gff\"\n",
    "    cls = CasContig.get_cas_info(gbff_file, gff_file)\n",
    "\n",
    "    if cls is not None:\n",
    "        # write to pandas dataframe\n",
    "        df_row = {\n",
    "            'biosample_accession': biosample_accession,\n",
    "            'organism': row['organism'],\n",
    "            'contig_id': cls.contig_id,\n",
    "            'cas_gene': cls.cas_type,\n",
    "            'locus_tag': cls.locus_tag,\n",
    "            'orientation': cls.orientation,\n",
    "            'start': cls.start,\n",
    "            'end': cls.end\n",
    "            }\n",
    "        rows.append(df_row)\n",
    "    else:\n",
    "        print(f\"No cas13b found for {biosample_accession} in {gbff_file} and {gff_file}\")\n",
    "        df_row = {\n",
    "            'biosample_accession': biosample_accession,\n",
    "            'organism': row['organism'],\n",
    "            'contig_id': None,\n",
    "            'cas_gene': None,\n",
    "            'locus_tag': None,\n",
    "            'orientation': None,\n",
    "            'start': None,\n",
    "            'end': None\n",
    "        }\n",
    "        rows.append(df_row)\n",
    "\n",
    "df_output = pd.DataFrame(rows)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = storage / \"cas13b_contigs.csv\"\n",
    "df_output.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f44f9",
   "metadata": {},
   "source": [
    "This revealed that not all samples from the inital databaset thought to carry the Cas13b gene had the gene present. Instead, a total of 68 genomes out of 105 samples had the cas13b gene annotated.<br>\n",
    "\n",
    "## CRISPR array prediction\n",
    "\n",
    "Due to CRIPSRidentify being installed in a separate conda enviroment, have to run this separately from the other modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f10282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run CRISPRidentify on the genomes that carries the cas13b gene\n",
    "from modules.crispr_detecion import CrisprDetection\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_table_from_db(file: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a table from a database and returns it as a pandas DataFrame.\n",
    "\n",
    "    args:\n",
    "        file (Path): Path to the database file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, header=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "storage = Path(\"/spacers_db/genomes\")\n",
    "df = read_table_from_db(f\"{storage}/cas13b_contigs.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row['cas_gene']) or row['cas_gene'] == \"\":\n",
    "        pass\n",
    "    else:\n",
    "        bioaccession = row['biosample_accession']\n",
    "        fasta_file = storage / f\"{bioaccession}.fna\"\n",
    "        # print(fasta_file)\n",
    "        CrisprDetection.run_crispridentify(fasta_file, storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfadf3c",
   "metadata": {},
   "source": [
    "## Data upload\n",
    "\n",
    "Once CRISPRidentify has completed running for all the samples, pull out results and upload to the cas13_bacterial_db. Results are written to two tables, cas13b_cripsrs and spacer_table. The cas13b_crisprs table contain information regarding all the predicted crispr array candidates and if they have passed the filter or not. \n",
    "\n",
    "Filter for array candidates the meet the following requirements:\n",
    "* Located within 20kb of the Cas13b gene\n",
    "* At least 4 spacers (this metric used by CRISPRCasFinder)\n",
    "* Average spacer length around 30bp\n",
    "* Average direct repeat length around 36bp\n",
    "\n",
    "The spacer_table stores information and sequences of spacers and direct repeats from all the predicted crispr array candidates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d51ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMN10691118\n",
      "SAMN06754876\n",
      "SAMN06289146\n",
      "SAMEA104200672\n",
      "SAMN05000968\n",
      "SAMN06184581\n",
      "SAMN13705423\n",
      "SAMN47059527\n",
      "SAMN04386100\n",
      "SAMN04487986\n",
      "SAMN28596590\n",
      "SAMN18133624\n",
      "SAMN25131779\n",
      "SAMD00078003\n",
      "SAMN04270979\n",
      "SAMN11047481\n",
      "SAMN02603919\n",
      "SAMN39216401\n",
      "SAMN41998628\n",
      "SAMN43911957\n",
      "SAMN40623457\n",
      "SAMN45156075\n",
      "SAMN45156076\n",
      "SAMN45934160\n",
      "SAMN10230162\n",
      "SAMN09907746\n",
      "SAMN19113859\n",
      "SAMN03761967\n",
      "SAMEA4063029\n",
      "SAMN04394637\n",
      "SAMN13111529\n",
      "SAMN07840095\n",
      "SAMN07836928\n",
      "SAMN07840081\n",
      "SAMN07840090\n",
      "SAMN07840091\n",
      "SAMN07840092\n",
      "SAMN07840094\n",
      "SAMN07840097\n",
      "SAMN07831761\n",
      "SAMN07836904\n",
      "SAMN07836934\n",
      "SAMN07315161\n",
      "SAMN07315160\n",
      "SAMN07315163\n",
      "SAMN18805464\n",
      "SAMN18805165\n",
      "SAMN18753385\n",
      "SAMN35301467\n",
      "SAMN35563277\n",
      "SAMD00060990\n",
      "SAMN03366764\n",
      "SAMN03372093\n",
      "SAMN03653671\n",
      "SAMN25263445\n",
      "SAMN02603988\n",
      "SAMD00034934\n",
      "SAMN04529095\n",
      "SAMN04529094\n",
      "SAMN07955957\n",
      "SAMN07956007\n",
      "SAMN07955952\n",
      "SAMN07956008\n",
      "SAMN07956010\n",
      "SAMN07955950\n",
      "SAMN07980911\n",
      "SAMN07980959\n",
      "SAMN07955960\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from modules.analysis_utils import ArrayCandidate\n",
    "from modules.genome_utils import CasContig\n",
    "import modules.database_utils as db_utils\n",
    "\n",
    "\n",
    "\n",
    "# read the cas13b contigs file\n",
    "storage = Path(\"/spacers_db/genomes\")\n",
    "df = db_utils.read_table_from_db(f\"{storage}/cas13b_contigs.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # check if the cas_gene is not NaN or empty\n",
    "    if pd.isna(row['cas_gene']) or row['cas_gene'] == \"\":\n",
    "        pass\n",
    "    else:\n",
    "        # Run data extraction\n",
    "        bioaccession = row['biosample_accession']\n",
    "        gbff_file = storage / f\"{bioaccession}.gbff\"\n",
    "        gff_file = storage / f\"{bioaccession}.gff\"\n",
    "        result_folder = Path(f\"/{storage}/{bioaccession}_crispridentify/{bioaccession}\")\n",
    "\n",
    "        candidates = ArrayCandidate.complie_crispr_arrays(result_folder, gbff_file, gff_file, storage)\n",
    "        filter_candidates = ArrayCandidate.filter_candidates(candidates, avg_dr_len=36, avg_spacer_len=30)\n",
    "\n",
    "        complete_candidates = []\n",
    "\n",
    "        for c in filter_candidates:\n",
    "            candidate = ArrayCandidate.get_spacer_dr_seq(c, result_folder)\n",
    "            # print(candidate)\n",
    "            if candidate is not None:\n",
    "                complete_candidates.append(candidate)\n",
    "\n",
    "\n",
    "        # Get the CasContig class instance for the given gbff and gff files\n",
    "        # This will extract the contig_id and other relevant information\n",
    "        cls = CasContig.get_cas_info(gbff_file, gff_file)\n",
    "\n",
    "\n",
    "        array_df = db_utils.generate_array_table(complete_candidates, cls)\n",
    "        spacer_df = db_utils.generate_spacer_table(complete_candidates)\n",
    "\n",
    "        # Upload the dataframes to the SQL database\n",
    "        db_utils.upload_arraytable_to_sql(array_df, \"cas13_bacterial_db\", \"cas13b_crisprs\")\n",
    "        db_utils.upload_spacertable_to_sql(spacer_df, \"cas13_bacterial_db\", \"spacer_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5df94",
   "metadata": {},
   "source": [
    "## Sequence analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7bd3f",
   "metadata": {},
   "source": [
    "# In progress\n",
    "\n",
    "Retrieved samples from the Cas13 bacterial database, searching through the ncbi_sra and ncbi_assembly_mono tables for the organism *Bacteroidales bacterium*, *Bergeyella zoohelcum*, *Segatella buccae* and *Prevotella pectinovora*, all reported to have the CRIPSR-Cas13b system.<br>\n",
    "\n",
    "Grab the data from the ncbi_sra.csv file and see how many samples are within allthebacteria database so we can use the assembly from there, avoid having to perform de novo assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import modules.database_utils as db_utils\n",
    "from modules.database_utils import Allthebacteria\n",
    "\n",
    "\n",
    "ncbi_sra_file = Path(\"/home/unimelb.edu.au/rbengtsson/work/spacer_analysis/prelim/data/ncbi_sra.csv\")\n",
    "\n",
    "sra_df, atb_merged_df = Allthebacteria.check_SRA_df(ncbi_sra_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfa8ba",
   "metadata": {},
   "source": [
    "A total of 92 samples from the 696 SRA samples are in the Allthebacteria database. We then need to inspect the ncbi_assembly.csv file and cross reference with samples within Allthebacteria datbase to ensure we don't have any redundant samples present across both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c739fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 5 samples from the 44 NCBI assembly samples are in Allthebacteria database.\n"
     ]
    }
   ],
   "source": [
    "# check for samples present in the assembly file and Allthebacteria file\n",
    "assembly_df = db_utils.read_table_from_db(\"prelim/data/ncbi_assembly.csv\")\n",
    "assembly_df['in_allthebacteria'] = assembly_df['biosampleaccn'].isin(atb_merged_df['sample_accession'])\n",
    "print(f\"A total of {assembly_df['in_allthebacteria'].sum()} samples from the {len(assembly_df)} NCBI assembly samples are in Allthebacteria database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc49359",
   "metadata": {},
   "source": [
    "Drop the 5 samples from the NCBI assembly dataset and use the ones in Allthebacteria dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc2a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_df = assembly_df[assembly_df['in_allthebacteria'] == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ff060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform analysis on 39 samples from NCBI assembly and 91 samples from Allthebacteria database.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Perform analysis on {len(assembly_df)} samples from NCBI assembly and {len(atb_merged_df)} samples from Allthebacteria database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e84716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4024695/4152738273.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assembly_subset_df['database'] = 'ncbi assembly'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Select relevant columns from the assembly dataframe\n",
    "columns_to_keep = ['biosampleaccn', 'organism', 'speciesname',\n",
    "                   'contign50', 'sequencingtechnology', 'ftppath_genbank', 'ftppath_assembly_rpt']\n",
    "assembly_subset_df = assembly_df[columns_to_keep]\n",
    "assembly_subset_df['database'] = 'ncbi assembly'\n",
    "\n",
    "atb_merged_df['database'] = 'allthebacteria'\n",
    "\n",
    "# Change column names to match Allthebacteria\n",
    "atb_merged_df.rename(columns={\n",
    "    'sample_accession': 'biosampleaccn',\n",
    "    'instrument_model': 'sequencingtechnology',\n",
    "    'n50': 'contign50'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "combined_df = pd.merge(assembly_subset_df, atb_merged_df, on=['biosampleaccn', 'organism','sequencingtechnology', 'contign50', 'database'], how='outer')\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "out_file = os.path.join('prelim', 'data', 'prelim_dataset_final.csv')\n",
    "combined_df.to_csv(out_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20267ef",
   "metadata": {},
   "source": [
    "Once we have the dataset, we now need to retrieve the fasta file. For samples coming from NCBI assembly database, we can directly fetch the fasta and gff files from the ftp provided.<br>\n",
    "\n",
    "Allthebacteria dataset only have assemblies avaliable. Going to continue with the 39 samples from NCBI assembly database for now, as genome annotation is avaliable for those samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8257ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.genome_utils as genome_utils\n",
    "\n",
    "prelim_data = db_utils.read_table_from_db(\"prelim/data/prelim_dataset_final.csv\")\n",
    "\n",
    "# Get the fasta files for the samples in the prelim_data\n",
    "ncbi_assembly_df = prelim_data[prelim_data['database'] == 'ncbi assembly']\n",
    "\n",
    "out_file_dir = Path(\"prelim/data/genomes\")\n",
    "\n",
    "if not out_file_dir.exists():\n",
    "    out_file_dir.mkdir(parents=True)\n",
    "\n",
    "# for index, row in ncbi_assembly_df.iterrows():\n",
    "#     biosample_accession = row['biosampleaccn']\n",
    "#     ftp_path = row['ftppath_genbank']\n",
    "#     gff_file_path = genome_utils.get_gff_from_ncbi(ftp_path, biosample_accession, out_file_dir)\n",
    "#     if gff_file_path is None:\n",
    "#         pass\n",
    "#     elif os.path.exists(gff_file_path):\n",
    "#         genome_utils.get_fasta_from_ncbi(ftp_path, biosample_accession, out_file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c25653",
   "metadata": {},
   "source": [
    "Majority of the samples were suppressed from NCBI and we are left with only 14 samples for the preliminary analysis.<br>\n",
    "\n",
    "Have to grab assemblies from allthebacteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78059e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the fasta files for the samples in the prelim_data\n",
    "# atb_assembly_df = prelim_data[prelim_data['database'] == 'allthebacteria']\n",
    "\n",
    "# for index, row in atb_assembly_df.iterrows():\n",
    "#     biosample_accession = row['biosampleaccn']\n",
    "#     genome_utils.get_fasta_from_allthebacteria(biosample_accession, out_file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45b9d3",
   "metadata": {},
   "source": [
    "## Genome annotation\n",
    "\n",
    "Once the assemblies have been retrieved, the next step is to perform genome annotation using PGAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06261321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499057d1",
   "metadata": {},
   "source": [
    "## Run CasFinder\n",
    "\n",
    "Search for cas13b gene in samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
